# ğŸš€ FAZA 2 BaÅŸlangÄ±Ã§ - Advanced ML & Dynamic Adaptation

**Tarih**: 12 Åubat 2026  
**Versiyon**: 3.3.2  
**Durum**: ğŸŸ¡ IN_PROGRESS  

---

## ğŸ“‹ FAZA 2 Nedir?

FAZA 1 ile mevcut analiz modÃ¼llerini entegre ederek signal kalitesini artÄ±rdÄ±k.  
**FAZA 2 amacÄ±**: Sistem kendini Ã¶ÄŸrenerek ve uyarlayarak **otomatik geliÅŸim** saÄŸlamak.

### Hedefler
- **ML Model EÄŸitimi**: Backtest verilerine dayalÄ± ML modeli eÄŸitmek
- **Parametreleri Dinamik Optimizasyon**: Piyasa koÅŸullarÄ±na gÃ¶re aÄŸÄ±rlÄ±klarÄ± otomatik ayarlamak
- **Portfolio-Level Optimizasyon**: TÃ¼m pozisyonlar iÃ§in en iyi risk/reward oranÄ±

---

## ğŸ¯ FAZA 2 Task Listesi

### Task 2.1: ML Training Pipeline OluÅŸtur
**Dosya**: `analysis/ml_training_pipeline.py`  
**Saati**: 6 saat  
**Kritiklik**: CRITICAL  

**AÃ§Ä±klama**:
- Backtest sonuÃ§larÄ±ndan train/test dataset oluÅŸtur
- Feature engineering (teknik gÃ¶sterge, pattern, volatilite, vb.)
- Model eÄŸitme (XGBoost, LightGBM, Random Forest)
- Model validasyonu ve cross-validation

**Inputs**:
- `backtest/backtester.py` Ã§Ä±ktÄ±sÄ± (historical trades)
- OHLCV verisi
- Teknik gÃ¶stergeler

**Outputs**:
- EÄŸitilmiÅŸ `.pkl` model dosyasÄ±
- Feature importance raporu
- Model accuracy metrikleri (Precision, Recall, F1)

---

### Task 2.2: Genetic Algorithm Parameter Optimization
**Dosya**: `analysis/parameter_optimizer.py`  
**Saati**: 8 saat  
**Kritiklik**: HIGH  

**AÃ§Ä±klama**:
- Integration Engine'in aÄŸÄ±rlÄ±klarÄ±nÄ± optimize et (0.25, 0.25, 0.30, 0.20)
- Piyasa rejimi bazÄ±nda farklÄ± aÄŸÄ±rlÄ±k setleri oluÅŸtur
- Backtest loop ile fitness evaluation yap
- Genetic algorithm ile en iyi kombinasyonu bul

**Parametre Setleri**:
```python
# Åu anda SABIT:
{
    "base_signal": 0.25,
    "confirmation": 0.25,
    "ml_confidence": 0.30,
    "entry_timing": 0.20
}

# FAZA 2 sonrasÄ± DINAMIK:
market_regimes = {
    "strong_uptrend": {"base": 0.20, "conf": 0.25, "ml": 0.35, "entry": 0.20},
    "weak_trend": {"base": 0.30, "conf": 0.30, "ml": 0.25, "entry": 0.15},
    "sideways": {"base": 0.25, "conf": 0.35, "ml": 0.25, "entry": 0.15},
}
```

---

### Task 2.3: Backtest to ML Training Loop
**Dosya**: `train_ml_model.py`  
**Saati**: 4 saat  
**Kritiklik**: HIGH  

**AÃ§Ä±klama**:
- Backtest Ã§alÄ±ÅŸtÄ±r â†’ SonuÃ§larÄ± topla
- BaÅŸarÄ±lÄ±/baÅŸarÄ±sÄ±z iÅŸlemleri label'le
- Features extract et
- ML modeli eÄŸit

**Workflow**:
```
1. Historical data oku (BIST 100, NASDAQ, vb.)
2. Backtest Ã§alÄ±ÅŸtÄ±r
3. Trade sonuÃ§larÄ±nÄ± veritabanÄ±na kaydet
   â”œâ”€ Win trades â†’ Label: 1 (baÅŸarÄ±lÄ±)
   â””â”€ Loss trades â†’ Label: 0 (baÅŸarÄ±sÄ±z)
4. Features oluÅŸtur ve normalize et
5. 80/20 train/test split
6. Model eÄŸit
7. Performance metrikleri hesapla
```

---

### Task 2.4: Portfolio-Level Optimization
**Dosya**: `risk/portfolio_optimizer.py`  
**Saati**: 6 saat  
**Kritiklik**: MEDIUM  

**AÃ§Ä±klama**:
- Tek sembol analizi â†’ Portfolio analizi
- Position sizing (her iÅŸlem iÃ§in en uygun miktar)
- Risk parity (tÃ¼m pozisyonlar eÅŸit risk taÅŸÄ±sÄ±n)
- Correlation matrix â†’ Diversifikasyon

---

## ğŸ“Š FAZA 2 Beklenen SonuÃ§lar

### Ã–nce (FAZA 1)
```
Signal Accuracy:        65% â†’ 85%
False Positive Rate:    35% â†’ 15%
Win Rate (Backtest):    48% â†’ 58%
```

### Sonra (FAZA 2)
```
Signal Accuracy:        85% â†’ 92%+ (ML model ile)
False Positive Rate:    15% â†’ 8%
Win Rate (Backtest):    58% â†’ 70%+
Sharpe Ratio:           0.8 â†’ 1.5+
```

---

## ğŸ”§ BaÅŸlamadan Ã–nce Kontrol Et

- [ ] Backtest sonuÃ§larÄ± kaydediliyor mu? (`backtest/backtester.py`)
- [ ] Trade verisi doÄŸru format mÄ±? (symbol, entry, exit, profit, vb.)
- [ ] Yeterli historical data var mÄ±? (minimum 6 ay)
- [ ] Feature engineering modÃ¼lleri mevcut mi? (`analysis/*.py`)

---

## ğŸ“ YaratÄ±lacak Dosyalar

### Yeni
- `analysis/ml_training_pipeline.py` (300+ lines)
- `risk/portfolio_optimizer.py` (250+ lines)
- `data_cache/ml_training_data.csv` (historical labeled data)
- `models/signal_predictor_v1.pkl` (eÄŸitilmiÅŸ ML model)

### GÃ¼ncellenecek
- `train_ml_model.py` (parametreler)
- `analysis/parameter_optimizer.py` (genetic algorithm)
- `scanner/symbol_analyzer.py` (dynamic weights)

---

## ğŸš¦ FAZA 2 BaÅŸlangÄ±Ã§ AdÄ±mlarÄ±

### AdÄ±m 1: ML Training Pipeline OluÅŸtur (6 saat)
```python
# analysis/ml_training_pipeline.py
class MLTrainingPipeline:
    def __init__(self, historical_trades_df):
        self.trades = historical_trades_df
        self.features = None
        self.model = None
    
    def prepare_data(self):
        # Dataset'i train/test'e bÃ¶l
        pass
    
    def extract_features(self):
        # Technical indicators'dan features oluÅŸtur
        pass
    
    def train_model(self):
        # XGBoost/LightGBM eÄŸitimi
        pass
    
    def evaluate(self):
        # Precision, Recall, F1 hesapla
        pass
```

### AdÄ±m 2: Parameter Optimizer'Ä± Kur (8 saat)
```python
# analysis/parameter_optimizer.py
class GeneticAlgorithmOptimizer:
    def __init__(self, cfg):
        self.population = []  # Weight combinations
        self.fitness_scores = []
    
    def create_population(self):
        # Random weight combinations oluÅŸtur
        pass
    
    def evaluate_fitness(self, weights):
        # Backtest Ã§alÄ±ÅŸtÄ±r, win rate'i return et
        pass
    
    def evolve(self, generations=50):
        # Selection, crossover, mutation
        pass
```

### AdÄ±m 3: Training Loop Kur (4 saat)
```python
# train_ml_model.py (FAZA 2 versiyonu)
def train_full_pipeline():
    # 1. Backtest verisi topla
    backtest_results = run_backtest_on_historical_data()
    
    # 2. ML model eÄŸit
    ml_pipeline = MLTrainingPipeline(backtest_results)
    model = ml_pipeline.train_model()
    
    # 3. Parametreleri optimize et
    optimizer = GeneticAlgorithmOptimizer(cfg)
    best_weights = optimizer.evolve(generations=100)
    
    # 4. En iyi modeli kaydet
    save_model(model)
    save_weights(best_weights)
```

---

## ğŸ“ˆ Success Metrics

### ML Model BaÅŸarÄ±sÄ±
- Accuracy: >85%
- Precision: >80% (false positive dÃ¼ÅŸÃ¼k)
- Recall: >75% (false negative dÃ¼ÅŸÃ¼k)
- AUC-ROC: >0.85

### Parameter Optimization
- Backtest win rate: +15% artÄ±ÅŸ
- Sharpe ratio: >1.2
- Max drawdown: <20%

### Portfolio Optimization
- Diversification index: >0.7
- Risk-adjusted return: +25%

---

## â° Timeline

```
12-20 Åub: ML Training Pipeline (Task 2.1)
20-28 Åub: Parameter Optimization (Task 2.2)
28-01 Mart: Backtest Loop (Task 2.3)
01-15 Mart: Portfolio Optimization (Task 2.4)
15-28 Mart: Testing & Validation
```

---

## ğŸ”— Ä°liÅŸkili Dosyalar

- [FAZA1_RELEASE_NOTES.md](FAZA1_RELEASE_NOTES.md) - Ã–nceki faz detaylarÄ±
- [DEVELOPMENT_ROADMAP.json](DEVELOPMENT_ROADMAP.json) - Tam roadmap
- [train_ml_model.py](train_ml_model.py) - ML training script
- [backtest/backtester.py](backtest/backtester.py) - Backtest engine

---

**Status**: âœ… FAZA 2 HazÄ±rlandÄ±  
**Next Step**: Task 2.1'i baÅŸlat (ML Training Pipeline)

